#!/usr/bin/env node
/**
 * 1-Click Creator - Full End-to-End Flow Test (UPDATED)
 * 
 * Tests complete workflow with Headless Mode (ChatGPT stable):
 * Step 1: Analyze with ChatGPT (Headless) âœ“
 * Step 2: Apply Recommendations
 * Step 3: Generate Images with Google Flow (2 images) âœ“
 * Step 4: Generate Videos with Google Flow (20s scenarios) âœ“
 * 
 * Configuration:
 * - ChatGPT analysis: HEADLESS MODE (no browser popup)
 * - Image provider: Google Flow (default)
 * - Video provider: Google Flow (now aligned with images)
 * - Image quantity: 2 (DESIRED_OUTPUT_COUNT)
 * - Video duration: 20 seconds (product-intro scenario)
 * 
 * Usage: node 03-oneclick-creator-fullflow-test.js
 */

import axios from 'axios';
import FormData from 'form-data';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const __dirname = path.dirname(fileURLToPath(import.meta.url));

const API_BASE = 'http://localhost:5000/api/flows';
const API_BASE_V1 = 'http://localhost:5000/api/v1';
const TIMEOUT = 600000; // 10 minutes for full flow with video generation

// Test configuration - Matches updated OneClickCreatorPage defaults
const TEST_CONFIG = {
  characterImage: 'test-images/anh-nhan-vat.jpeg',
  productImage: 'test-images/anh-san-pham.png',
  
  // Image Generation (aligned with ImageGenerationPage)
  quantity: 2,  // DESIRED_OUTPUT_COUNT = 2
  imageProvider: 'google-flow',  // Google Flow for consistent quality
  
  // Video Generation (now aligned with VideoGenerationPage)
  videoDuration: 20,  // Total duration in seconds
  videoScenario: 'product-intro',  // VIDEO_SCENARIOS default
  videoProvider: 'google-flow',  // Aligned with image provider
  
  // Analysis & Settings
  analysisProvider: 'chatgpt-browser', // Using ChatGPT
  headless: true,  // ðŸ’« NEW: Run ChatGPT in headless mode (stable service)
  
  useCase: 'change-clothes',
  productFocus: 'full-outfit',
  
  settings: {
    scene: 'studio',
    lighting: 'soft-diffused',
    mood: 'confident',
    style: 'minimalist',
    colorPalette: 'neutral',
    cameraAngle: 'eye-level',
    aspectRatio: '16:9'
  }
};

// Colors for terminal output
const colors = {
  reset: '\x1b[0m',
  green: '\x1b[32m',
  red: '\x1b[31m',
  yellow: '\x1b[33m',
  blue: '\x1b[34m',
  cyan: '\x1b[36m',
  magenta: '\x1b[35m'
};

const log = {
  info: (msg) => console.log(`${colors.blue}â„¹ï¸  ${msg}${colors.reset}`),
  success: (msg) => console.log(`${colors.green}âœ“ ${msg}${colors.reset}`),
  error: (msg) => console.log(`${colors.red}âœ— ${msg}${colors.reset}`),
  warn: (msg) => console.log(`${colors.yellow}âš ï¸  ${msg}${colors.reset}`),
  test: (msg) => console.log(`\n${colors.magenta}ðŸ§ª ${msg}${colors.reset}`),
  step: (num, title, provider = null) => {
    const icon = {
      'chatgpt-browser': 'ðŸ¤–',
      'google-flow': 'ðŸŒ',
      'grok': 'ðŸš€'
    }[provider] || 'âš™ï¸';
    const providerStr = provider ? ` (${provider})` : '';
    console.log(`\n${colors.cyan}â•â•â• STEP ${num}: ${title}${providerStr} ${icon} â•â•â•${colors.reset}`);
  },
  section: (title) => {
    console.log(`\n${colors.magenta}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`);
    console.log(`${title}`);
    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${colors.reset}`);
  }
};

let testResults = {
  startTime: Date.now(),
  steps: {},
  totalDuration: 0,
  success: false
};

async function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

async function checkServer() {
  log.test('Checking server availability...');
  try {
    await axios.get(`${API_BASE}/../health`, { timeout: 5000 });
    log.success('Server is running');
    return true;
  } catch (error) {
    log.error(`Server is not available at ${API_BASE}`);
    log.info('Make sure to run: npm run dev (in backend directory)');
    process.exit(1);
  }
}

async function verifyTestImages() {
  log.test('Verifying test images...');
  
  // Build paths: __dirname is at backend/tests/4-workflows, so go up 2 to get to backend
  const backendDir = path.join(__dirname, '../../');
  
  for (const [key, imagePath] of Object.entries({
    character: TEST_CONFIG.characterImage,
    product: TEST_CONFIG.productImage
  })) {
    const fullPath = path.join(backendDir, imagePath);
    console.log(`   Checking: ${fullPath}`);
    if (!fs.existsSync(fullPath)) {
      log.error(`Missing ${key} image: ${fullPath}`);
      process.exit(1);
    }
    const stats = fs.statSync(fullPath);
    log.success(`${key}: ${imagePath} (${(stats.size / 1024).toFixed(2)} KB)`);
  }
}

async function testStep1Analysis() {
  log.step(1, 'Analyze Images with ChatGPT', 'chatgpt-browser');
  
  testResults.steps['analysis'] = {
    startTime: Date.now(),
    provider: TEST_CONFIG.analysisProvider,
    status: 'running'
  };

  try {
    log.info('Preparing analysis request...');
    log.info(`Provider: ${TEST_CONFIG.analysisProvider}`);
    log.info(`Settings: ${JSON.stringify(TEST_CONFIG.settings)}`);

    const backendDir = path.join(__dirname, '../../');
    const form = new FormData();
    form.append('characterImage', fs.createReadStream(
      path.join(backendDir, TEST_CONFIG.characterImage)
    ));
    form.append('productImage', fs.createReadStream(
      path.join(backendDir, TEST_CONFIG.productImage)
    ));
    form.append('useCase', TEST_CONFIG.useCase);
    form.append('productFocus', TEST_CONFIG.productFocus);
    form.append('analysisProvider', TEST_CONFIG.analysisProvider);
    
    // Add settings
    Object.entries(TEST_CONFIG.settings).forEach(([key, value]) => {
      form.append(key, value);
    });

    log.info('Sending analysis request to backend... (waiting for ChatGPT automation)');
    console.log(`  â³ This may take 30-60s while ChatGPT browser automation runs...`);

    const response = await axios.post(`${API_BASE}/analyze`, form, {
      headers: form.getHeaders(),
      timeout: TIMEOUT,
      maxRedirects: 5
    });

    if (!response.data.success && !response.data.data) {
      throw new Error(`Invalid response: ${JSON.stringify(response.data).substring(0, 200)}`);
    }

    const analysisData = response.data.data || response.data;
    testResults.steps['analysis'].duration = Date.now() - testResults.steps['analysis'].startTime;
    testResults.steps['analysis'].status = 'completed';
    testResults.steps['analysis'].result = analysisData;

    log.success('Analysis completed with ChatGPT!');
    
    if (analysisData.analysis?.character) {
      log.info(`Character: ${analysisData.analysis.character.name || 'Analyzed'}`);
    }
    if (analysisData.analysis?.product) {
      log.info(`Product: ${analysisData.analysis.product.garmentType || 'Clothing analyzed'}`);
    }
    if (analysisData.analysis?.recommendations) {
      log.info(`âœ“ Recommendations extracted for styling`);
    }

    return analysisData;

  } catch (error) {
    testResults.steps['analysis'].status = 'failed';
    testResults.steps['analysis'].error = error.message;
    testResults.steps['analysis'].duration = Date.now() - testResults.steps['analysis'].startTime;

    log.error(`Analysis failed: ${error.message}`);
    if (error.response?.data?.error) {
      log.info(`Backend error: ${error.response.data.error}`);
    }
    throw error;
  }
}

async function testStep2ApplyRecommendations(analysisData) {
  log.step(2, 'Apply Recommendations');
  
  testResults.steps['recommendations'] = {
    startTime: Date.now(),
    status: 'running'
  };

  try {
    log.info('Extracting recommendations from analysis...');

    let recommendedOptions = {
      scene: TEST_CONFIG.settings.scene,
      lighting: TEST_CONFIG.settings.lighting,
      mood: TEST_CONFIG.settings.mood,
      style: TEST_CONFIG.settings.style,
      colorPalette: TEST_CONFIG.settings.colorPalette,
      cameraAngle: TEST_CONFIG.settings.cameraAngle
    };

    if (analysisData?.analysis?.recommendations) {
      const rec = analysisData.analysis.recommendations;
      if (rec.scene?.choice) recommendedOptions.scene = rec.scene.choice;
      if (rec.lighting?.choice) recommendedOptions.lighting = rec.lighting.choice;
      if (rec.mood?.choice) recommendedOptions.mood = rec.mood.choice;
      if (rec.style?.choice) recommendedOptions.style = rec.style.choice;
      if (rec.colorPalette?.choice) recommendedOptions.colorPalette = rec.colorPalette.choice;
      if (rec.cameraAngle?.choice) recommendedOptions.cameraAngle = rec.cameraAngle.choice;
      
      log.success('âœ“ Applied ChatGPT recommendations');
      log.info(`Final settings: ${JSON.stringify(recommendedOptions)}`);
    } else {
      log.warn('No custom recommendations, using defaults');
    }

    testResults.steps['recommendations'].duration = Date.now() - testResults.steps['recommendations'].startTime;
    testResults.steps['recommendations'].status = 'completed';
    testResults.steps['recommendations'].result = recommendedOptions;

    return recommendedOptions;

  } catch (error) {
    testResults.steps['recommendations'].status = 'failed';
    testResults.steps['recommendations'].error = error.message;
    testResults.steps['recommendations'].duration = Date.now() - testResults.steps['recommendations'].startTime;
    
    log.error(`Failed to apply recommendations: ${error.message}`);
    throw error;
  }
}

async function testStep3GenerateImage(analysisData, recommendedOptions) {
  log.step(3, 'Generate Images', TEST_CONFIG.imageProvider);
  
  testResults.steps['image-generation'] = {
    startTime: Date.now(),
    provider: TEST_CONFIG.imageProvider,
    imageCount: TEST_CONFIG.quantity,
    status: 'running'
  };

  try {
    log.info('Preparing image generation with full analysis + styling options...');

    // Build selectedOptions from recommended options
    const selectedOptions = {
      scene: recommendedOptions.scene,
      lighting: recommendedOptions.lighting,
      mood: recommendedOptions.mood,
      style: recommendedOptions.style,
      colorPalette: recommendedOptions.colorPalette,
      cameraAngle: recommendedOptions.cameraAngle,
      hairstyle: 'same',  // Keep character same
      // Add any additional styling from analysis
      ...(analysisData?.analysis?.stylingNotes || {})
    };

    log.info(`Quantity: ${TEST_CONFIG.quantity} images (DESIRED_OUTPUT_COUNT)`);
    log.info(`Calling ${TEST_CONFIG.imageProvider} for image generation...`);
    console.log(`  â³ Image generation in progress... (typically 1-2 minutes)`);

    // NEW: Pass analysis + selectedOptions to backend for proper prompt building
    const response = await axios.post(
      `${API_BASE}/generate`,
      {
        analysis: analysisData?.analysis,  // Pass full analysis object
        selectedOptions: selectedOptions,  // Pass styling options
        imageCount: TEST_CONFIG.quantity,
        imageSize: '1024x1024',
        imageProvider: TEST_CONFIG.imageProvider,
        useCase: TEST_CONFIG.useCase,
        productFocus: TEST_CONFIG.productFocus
      },
      {
        timeout: TIMEOUT
      }
    );

    if (!response.data.success && !response.data.data) {
      throw new Error(`Invalid response: ${JSON.stringify(response.data).substring(0, 200)}`);
    }

    const responseData = response.data.data || response.data;
    const images = responseData.generatedImages || responseData.images || [];
    testResults.steps['image-generation'].duration = Date.now() - testResults.steps['image-generation'].startTime;
    testResults.steps['image-generation'].status = 'completed';
    testResults.steps['image-generation'].result = {
      imageCount: images.length,
      firstImageUrl: images[0]?.url || images[0]?.image || 'Unknown',
      fullResponse: JSON.stringify(response.data).substring(0, 200)
    };

    if (images.length === 0) {
      log.warn(`No images generated by ${TEST_CONFIG.imageProvider}`);
      log.info(`Full response: ${JSON.stringify(response.data).substring(0, 300)}`);
      return null;
    }

    log.success(`Image generated successfully!`);
    log.info(`Provider: ${TEST_CONFIG.imageProvider}`);
    log.info(`Generated images: ${images.length}`);
    
    return images[0];

  } catch (error) {
    testResults.steps['image-generation'].status = 'failed';
    testResults.steps['image-generation'].error = error.message;
    testResults.steps['image-generation'].duration = Date.now() - testResults.steps['image-generation'].startTime;

    log.error(`Image generation failed: ${error.message}`);
    if (error.response?.data?.error) {
      log.info(`Backend error: ${error.response.data.error}`);
    }
    throw error;
  }
}

async function testStep4GenerateVideos(analysisData, generatedImage) {
  log.step(4, 'Generate Videos', TEST_CONFIG.videoProvider);
  
  testResults.steps['video-generation'] = {
    startTime: Date.now(),
    provider: TEST_CONFIG.videoProvider,
    videoDuration: TEST_CONFIG.videoDuration,
    videoScenario: TEST_CONFIG.videoScenario,
    status: 'running'
  };

  try {
    log.info('Building video prompt from analysis...');

    // Use scenario-based prompt (matching VideoGenerationPage behavior)
    const videoPrompt = `Professional fashion video showcasing ${TEST_CONFIG.productFocus}. ` +
      `Scenario: ${TEST_CONFIG.videoScenario}. ` +
      `Scene: ${TEST_CONFIG.settings.scene}. ` +
      `Lighting: ${TEST_CONFIG.settings.lighting}. ` +
      `Mood: ${TEST_CONFIG.settings.mood}. ` +
      `Style: ${TEST_CONFIG.settings.style}. ` +
      `Duration: ${TEST_CONFIG.videoDuration} seconds. High quality, professional fashion video.`;

    log.info(`Video Provider: ${TEST_CONFIG.videoProvider}`);
    log.info(`Video Duration: ${TEST_CONFIG.videoDuration} seconds`);
    log.info(`Video Scenario: ${TEST_CONFIG.videoScenario}`);
    log.info(`Prompt: ${videoPrompt.substring(0, 100)}...`);
    
    console.log(`\n  â³ Video generation in progress...`);
    console.log(`  â„¹ï¸  Provider: ${TEST_CONFIG.videoProvider}`);
    console.log(`  â„¹ï¸  Duration: ${TEST_CONFIG.videoDuration}s`);
    
    if (!TEST_CONFIG.headless) {
      console.log(`  â„¹ï¸  Browser window will open for interaction\n`);
    } else {
      console.log(`  â„¹ï¸  Headless mode enabled (ChatGPT stable)\n`);
    }

    // Google Flow requires browser interaction for video (but ChatGPT is headless)
    if (TEST_CONFIG.videoProvider === 'google-flow') {
      log.info(`ðŸ“ Google Flow video generation via browser automation`);
      
      // Format matches /generate-video endpoint expectations
      const videoSegments = [
        videoPrompt,  // Single segment (could be split based on duration)
      ];

      const videoPayload = {
        duration: TEST_CONFIG.videoDuration,
        scenario: TEST_CONFIG.videoScenario,
        segments: videoSegments,
        videoProvider: 'google-flow',
        headless: TEST_CONFIG.headless || false  // Pass headless mode config
      };

      log.info(`Sending request to Google Flow video endpoint...`);
      log.info(`Configuration: ${JSON.stringify({ 
        duration: TEST_CONFIG.videoDuration,
        scenario: TEST_CONFIG.videoScenario,
        headless: TEST_CONFIG.headless
      })}`);
      
      const response = await axios.post(
        `${API_BASE_V1}/browser-automation/generate-video`,
        videoPayload,
        {
          timeout: TIMEOUT,
          maxRedirects: 5
        }
      );

      if (!response.data.success) {
        throw new Error(response.data.error || 'Google Flow video generation failed');
      }

      const videoData = response.data.data || response.data;
      testResults.steps['video-generation'].duration = Date.now() - testResults.steps['video-generation'].startTime;
      testResults.steps['video-generation'].status = 'completed';
      
      const videoUrl = videoData.videoUrl || videoData.url || videoData.video_url || 
                       videoData.generatedVideo || 'Video generation started...';
      
      testResults.steps['video-generation'].result = {
        videoUrl: videoUrl,
        provider: 'google-flow',
        duration: TEST_CONFIG.videoDuration,
        scenario: TEST_CONFIG.videoScenario,
        status: videoData.status || 'generated'
      };

      log.success(`âœ… Video generated successfully!`);
      if (videoUrl && videoUrl !== 'Video generation started...') {
        log.info(`Video URL: ${videoUrl.substring(0, 100)}...`);
      }
      log.info(`Response keys: ${Object.keys(videoData).join(', ')}`);

      return videoData;
    }

    // Fallback for other providers (Grok, etc.)
    const videoPayload = {
      videoProvider: TEST_CONFIG.videoProvider,
      prompt: videoPrompt,
      duration: TEST_CONFIG.videoDuration,
      scenario: TEST_CONFIG.videoScenario,
      quality: 'high',
      aspectRatio: TEST_CONFIG.settings.aspectRatio || '16:9'
    };

    const response = await axios.post(
      `${API_BASE_V1}/browser-automation/generate-video-with-provider`,
      videoPayload,
      { timeout: TIMEOUT }
    );

    const videoData = response.data.data || response.data;
    testResults.steps['video-generation'].duration = Date.now() - testResults.steps['video-generation'].startTime;
    testResults.steps['video-generation'].status = 'completed';
    
    log.success(`Video generated successfully!`);
    log.info(`Provider: ${videoData.provider || TEST_CONFIG.videoProvider}`);
    log.info(`Duration: ${TEST_CONFIG.videoDuration}s`);
    log.info(`Scenario: ${TEST_CONFIG.videoScenario}`);

    return videoData;

  } catch (error) {
    testResults.steps['video-generation'].status = 'failed';
    testResults.steps['video-generation'].error = error.message;
    testResults.steps['video-generation'].duration = Date.now() - testResults.steps['video-generation'].startTime;

    log.warn(`âš ï¸  Video generation failed: ${error.message}`);
    if (error.response?.data) {
      log.info(`Backend response: ${JSON.stringify(error.response.data).substring(0, 200)}`);
    }
    log.info(`Note: Video generation is optional. Continuing with test...`);
    return null;
  }
}

async function printSummary() {
  log.section('TEST SUMMARY - 1-Click Creator Full Flow');
  
  let allSuccess = true;
  const totalDuration = Date.now() - testResults.startTime;

  console.log('\nðŸ“Š Results by Step:');
  console.log('');

  for (const [stepName, stepData] of Object.entries(testResults.steps)) {
    const status = stepData.status === 'completed' ? 'âœ“' : 'âœ—';
    const statusColor = stepData.status === 'completed' ? colors.green : colors.red;
    const duration = (stepData.duration / 1000).toFixed(2);
    
    console.log(`${statusColor}${status}${colors.reset} ${stepName.padEnd(20)} | Duration: ${duration}s`);
    
    if (stepData.error) {
      console.log(`  â””â”€ Error: ${stepData.error}`);
      allSuccess = false;
    }
    
    // Print relevant configuration for each step
    if (stepName === 'image-generation' && stepData.imageCount) {
      console.log(`  â””â”€ Generated: ${stepData.imageCount} images (DESIRED_OUTPUT_COUNT)`);
    }
    if (stepName === 'video-generation' && stepData.videoDuration) {
      console.log(`  â””â”€ Config: ${stepData.videoDuration}s duration, ${stepData.videoScenario} scenario`);
    }
  }

  console.log('');
  console.log(`â±ï¸  Total Time: ${(totalDuration / 1000).toFixed(2)}s`);
  
  // Summary with enhanced messaging
  if (testResults.steps['video-generation']?.status === 'completed') {
    console.log(`\n${colors.green}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`);
    console.log(`âœ… FULL END-TO-END TEST PASSED - All steps completed!`);
    console.log(`\nâœ“ Step 1: ChatGPT Analysis (Headless Mode)`);
    console.log(`âœ“ Step 2: Recommendations Applied`);
    console.log(`âœ“ Step 3: ${TEST_CONFIG.quantity} Images Generated (${TEST_CONFIG.imageProvider})`);
    console.log(`âœ“ Step 4: ${testResults.steps['video-generation']?.videoDuration || 20}s Videos Generated (${TEST_CONFIG.videoProvider})`);
    console.log(`\nðŸ“ Configuration Summary:`);
    console.log(`   â€¢ Analysis: ChatGPT Browser (Headless: ${TEST_CONFIG.headless ? 'Enabled' : 'Disabled'})`);
    console.log(`   â€¢ Images: ${TEST_CONFIG.quantity} Ã— ${TEST_CONFIG.imageProvider}`);
    console.log(`   â€¢ Videos: ${TEST_CONFIG.videoDuration}s Ã— ${TEST_CONFIG.videoScenario} scenario`);
    console.log(`\nðŸŽ¯ All defaults match OneClickCreatorPage v2 configuration`);
    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${colors.reset}`);
  } else if (testResults.steps['image-generation']?.status === 'completed') {
    console.log(`\n${colors.yellow}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`);
    console.log(`âš ï¸  PARTIAL SUCCESS - Image generation completed`);
    console.log(`âœ“ ChatGPT Analysis`);
    console.log(`âœ“ Recommendations Applied`);
    console.log(`âœ“ ${TEST_CONFIG.quantity} Images Generated`);
    console.log(`âœ— Videos - check logs for details (optional step)`);
    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${colors.reset}`);
  } else if (testResults.steps['analysis']?.status === 'completed') {
    console.log(`\n${colors.yellow}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`);
    console.log(`âš ï¸  PARTIAL SUCCESS - Analysis completed`);
    console.log(`âœ“ ChatGPT Analysis`);
    console.log(`âœ— Image generation - check logs for details`);
    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${colors.reset}`);
  } else {
    console.log(`\n${colors.red}â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”`);
    console.log(`âŒ TEST FAILED - Check errors above`);
    console.log(`â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”${colors.reset}`);
  }
  
  console.log('\nðŸ’¡ Tips:');
  console.log('   â€¢ For headless mode issues, check ChatGPT service logs');
  console.log('   â€¢ Video generation time depends on content complexity (2-10 min)');
  console.log('   â€¢ All configurations align with OneClickCreatorPage v2 defaults');
}

// ============================================================
// MAIN TEST EXECUTION
// ============================================================

async function runFullTest() {
  log.section('1-CLICK CREATOR FULL FLOW TEST');
  
  console.log('\nðŸ“‹ Test Configuration:');
  console.log(`  â€¢ Analysis Provider: ${TEST_CONFIG.analysisProvider} (ChatGPT) âœ“ NEW`);
  console.log(`  â€¢ Image Provider: ${TEST_CONFIG.imageProvider}`);
  console.log(`  â€¢ Video Provider: ${TEST_CONFIG.videoProvider}`);
  console.log(`  â€¢ Quality Settings: ${JSON.stringify(TEST_CONFIG.settings)}`);
  console.log(`  â€¢ Use Case: ${TEST_CONFIG.useCase}`);
  console.log(`  â€¢ Product Focus: ${TEST_CONFIG.productFocus}`);

  try {
    // Pre-flight checks
    await checkServer();
    await verifyTestImages();

    // Step 1: Analysis
    const analysisData = await testStep1Analysis();

    // Step 2: Apply Recommendations  
    const recommendedOptions = await testStep2ApplyRecommendations(analysisData);

    // Step 3: Generate Image
    let generatedImage = null;
    try {
      generatedImage = await testStep3GenerateImage(analysisData, recommendedOptions);
    } catch (imageError) {
      log.warn(`Step 3 failed, continuing to Step 4 anyway...`);
    }

    // Step 4: Generate Videos
    await testStep4GenerateVideos(analysisData, generatedImage);

    // Print results
    await printSummary();

  } catch (error) {
    log.error(`Test execution failed at critical step: ${error.message}`);
    await printSummary();
    process.exit(1);
  }
}

// Run the test
runFullTest().catch(err => {
  log.error(`Unexpected error: ${err.message}`);
  process.exit(1);
});
